/**
 * Re-indexar documentos do Blob Storage no Redis
 * Aplica novas regras de indexaÃ§Ã£o: TODAS as palavras + formataÃ§Ã£o avanÃ§ada preservada
 */

import { list } from '@vercel/blob';
import Redis from 'ioredis';
import mammoth from 'mammoth';
import dotenv from 'dotenv';
import { processDocx, sectionsToJson } from './docx-processor.js';

// Carregar variÃ¡veis de ambiente
dotenv.config();

async function reindexDocuments() {
  console.log('ðŸ”„ Iniciando re-indexaÃ§Ã£o de documentos com formataÃ§Ã£o avanÃ§ada...\n');

  // Conectar ao Redis
  const redis = new Redis(process.env.REDIS_URL || process.env.KV_REST_API_URL);

  try {
    // 1. Listar todos os blobs
    console.log('ðŸ“‹ Listando documentos no Blob Storage...');
    const { blobs } = await list({
      token: process.env.BLOB_READ_WRITE_TOKEN,
      prefix: 'docs/'
    });

    console.log(`Encontrados ${blobs.length} documentos\n`);

    // 2. Para cada blob, baixar, processar e re-indexar
    for (const blob of blobs) {
      try {
        const filename = blob.pathname.replace('docs/', '');
        
        if (!filename.endsWith('.docx')) {
          console.log(`â­ï¸  Ignorando ${filename} (nÃ£o Ã© .docx)`);
          continue;
        }

        console.log(`\nðŸ“„ Processando: ${filename}`);
        
        // Baixar o arquivo
        const response = await fetch(blob.url);
        const arrayBuffer = await response.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);

        // Processar com formataÃ§Ã£o avanÃ§ada
        console.log('   ðŸ” Extraindo formataÃ§Ã£o avanÃ§ada...');
        const processed = await processDocx(buffer);
        const content = processed.content;
        const sectionsJson = sectionsToJson(processed.sections);

        console.log(`   âœ… ${processed.sections.length} seÃ§Ãµes estruturadas`);
        console.log(`   ðŸ“Š ${processed.metadata.wordCount} palavras, ${processed.metadata.paragraphCount} parÃ¡grafos`);
        console.log(`   ðŸ”— Links: ${processed.metadata.hasLinks ? 'Sim' : 'NÃ£o'}, Tabelas: ${processed.metadata.hasTables ? 'Sim' : 'NÃ£o'}`);

        // Gerar ID
        const title = filename.replace('.docx', '');
        const id = title
          .toLowerCase()
          .normalize('NFD')
          .replace(/[\u0300-\u036f]/g, '')
          .replace(/[^a-z0-9]+/g, '-')
          .replace(/^-+|-+$/g, '');

        console.log(`   ID: doc:${id}`);

        // Gerar keywords (TODAS as palavras Ãºnicas)
        const words = content
          .toLowerCase()
          .normalize('NFD')
          .replace(/[\u0300-\u036f]/g, '')
          .replace(/[^a-z0-9\s]/g, ' ')
          .split(/\s+/)
          .filter(w => w.length > 3);
        
        const uniqueWords = [...new Set(words)];
        const keywords = uniqueWords.join(' ');

        console.log(`   Palavras Ãºnicas: ${uniqueWords.length}`);
        console.log(`   Tamanho do conteÃºdo: ${content.length} caracteres`);

        // Atualizar no Redis com formataÃ§Ã£o preservada
        const documentData = {
          id,
          title,
          keywords,
          description: content, // Sem limite - conteÃºdo completo
          content,
          sections: sectionsJson, // SeÃ§Ãµes estruturadas com formataÃ§Ã£o
          icon: 'file-text',
          color: JSON.stringify({ bg: 'blue', text: 'white' }),
          externalLink: '',
          lastModified: blob.uploadedAt || new Date().toISOString(),
          createdAt: blob.uploadedAt || new Date().toISOString(),
          blobUrl: blob.url,
          metadata: JSON.stringify(processed.metadata)
        };

        await redis.hset(`doc:${id}`, ...Object.entries(documentData).flat());
        await redis.sadd('docs:all', id);

        // Limpar Ã­ndices antigos deste documento
        console.log(`   ðŸ§¹ Limpando Ã­ndices antigos...`);
        const searchKeys = await redis.keys('search:*');
        for (const key of searchKeys) {
          await redis.srem(key, id);
        }

        // Re-indexar TODAS as palavras Ãºnicas
        console.log(`   ðŸ” Indexando ${uniqueWords.length} palavras...`);
        for (const word of uniqueWords) {
          if (word.length > 3) {
            await redis.sadd(`search:${word.toLowerCase()}`, id);
          }
        }

        console.log(`   âœ… Re-indexado com sucesso!`);

      } catch (error) {
        console.error(`   âŒ Erro ao processar ${blob.pathname}:`, error.message);
      }
    }

    console.log('\n\nâœ… Re-indexaÃ§Ã£o concluÃ­da!');
    console.log(`ðŸ“Š Total de documentos processados: ${blobs.length}`);

  } catch (error) {
    console.error('âŒ Erro durante re-indexaÃ§Ã£o:', error);
    throw error;
  } finally {
    await redis.quit();
  }
}

// Executar
reindexDocuments().catch(error => {
  console.error('Erro fatal:', error);
  process.exit(1);
});
